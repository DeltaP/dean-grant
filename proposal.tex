\documentclass[11pt]{article}
\usepackage[margin=1.0in]{geometry}
\usepackage{sectsty}
\sectionfont{\large}

\begin{document}
  \title{GPU's for Lattice Field Theory}
  \author{Anqi Cheng}
  \maketitle

  \section*{Overview} %although the layout may seem awkward this is the paragraph that they say should have all the information....
  In this project  I propose to use a \$10,000 grant to build a workstation with two of NVIDIA's latest  Graphics Processing Units (GPUs), the Kepler K20.
  This workstation will be used for GPU code development and data analysis for the doctoral dissertation of myself as well as another graduate student in our group, Gregory Petropoulos.\\
  
  \section*{GPUs for Frontier Physics}
  Strongly coupled quantum field theories play an important role in Nature.
  The best example is the strong nuclear force which is responsible for atomic nuclei existing.
  These problems were largely intractable because of their non-perturbative nature until lattice field theory turned an impossible analytic task into a difficult numerical task by putting it on a computer.
  Because studying strongly coupled quantum field theories  on a computer is numerically intensive, lattice field theory is always on the cutting edge of scientific computing. \\\\
 The highly parallel and energy efficient architecture of GPUs makes them attractive for high performance computing, however until relatively recently they were difficult to program.  
 This changed when NVIDIA launched the CUDA language and the Tesla series of GPUs that are specifically aimed at making GPU programming more accessible to the scientific community.
  Since then GPUs have become a very attractive platform for lattice field theory simulations, and QUDA, a lattice-CUDA library \cite{QUDA1,QUDA2,QUDA3} is in active development.
   Codes developed with CUDA and qUDA are already run on large GPU clusters such as the Edge cluster at LLNL, Dsg cluster at FNAL, and 10g cluster at JLab.
  Additionally, a new generation of CPU/GPU hybrid machines are arriving; earlier this year one of these hybrid machines, Titan, took its place as the fastest supercomputer.\\\\
  It is clear that GPUs will play an ever increasing role in the future of scientific computing. 
  The proposed workstation has a peak theoretical performance of 2.5 trillion floating point operations per second (TFLOP/s).
  To put that in prospective, that is equivalent to the fastest supercomputers only 10 years ago.
  Not only will it allow me to adapt our current code to run on GPUs and become an active developer for the lattice QUDA community, but also as a dedicated computational resource it will greatly accelerate the speed at which we can measure and analyze data generated on the larger computers that we have access to.
  By moving toward GPU programming our group will be able to take part in cutting edge code development that will allow us to run on the fastest supercomputers of today and tomorrow.
    
   \section*{Methods} % describe the lattice work flow
  In lattice field theories nHYP smearing is a widely used method developed by CU researchers. 
  In this project I will first try to adapt this method for GPUs, and then use it as an element in the Dirac eigenmode measurements, the major work of my doctoral dissertation. The long term goal will be adapting large-scale computation code on GPUs that serves the research of our group. This is the driving force for having two GPU cards; we will be able to test all the inter-card communication of our code locally and make sure it can scale well. Once getting there we will be able to apply computer time on the public GPU cluster resources. 
    
  \section*{Qualifications} %classic brag sheet
  I am already a proficient coder and have experience writing serial and parallel programs.
  Last semester I took a high performance scientific computation class from the Computer Science Department, which strengthened my background in large-scale parallelism.
  Finally I attended lectures on GPU programming given by Michael Clark, a QUDA developer at NVIDIA, at the USQCD All Hands' Meeting in Fermilab last April and at the INT summer program held by University of Washington last August. 
  From these lectures I developed an basic understanding of GPU computing and its application to lattice gauge theory. 
  With the knowledge and skills I mentioned above I am confident to successfully accomplish this project.

% ---- Bibliography ----
%
\begin{thebibliography}{99}
\bibitem{QUDA1}
http://lattice.github.com/quda/
\bibitem{QUDA2}
M. A. Clark, R. Babich, K. Barros, R. C. Brower, and C. Rebbi,
``Solving Lattice QCD systems of equations using mixed precision solvers on GPUs" Comput. Phys. Commun., vol. 181, 2010, p. 1517. [arXiv:0911.3191 
[hep-lat]]
\bibitem{QUDA3}
R. Babich, M. A. Clark, B. Jo$\acute{o}$ ``Parallelizing the QUDA Library for Multi-GPU Calculations in Lattice Quantum Chromodynamics" [arXiv:1011.0024 
[hep-lat]]

\end{thebibliography}

\end{document}
